import torch
from tqdm import tqdm
from pathlib import Path
import numpy as np

class Runner:
    """
    ä¸€ä¸ªå°è£…äº†å®Œæ•´è®­ç»ƒ/éªŒè¯å¾ªç¯çš„æ‰§è¡Œå™¨ã€‚
    å®ƒè´Ÿè´£ç®¡ç†è®­ç»ƒçŠ¶æ€ã€æ‰§è¡Œè®­ç»ƒå¾ªç¯ã€è°ƒç”¨é’©å­ã€è¿›è¡ŒéªŒè¯å’Œä¿å­˜æ¨¡å‹ã€‚
    """
    def __init__(self, model, optimizer, criterion, metric,
                 train_loader, val_loader, lr_scheduler, 
                 hooks, cfg):
        
        # --- æ ¸å¿ƒç»„ä»¶ ---
        self.model = model
        self.optimizer = optimizer
        self.criterion = criterion
        self.metric = metric
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.lr_scheduler = lr_scheduler
        self.hooks = hooks
        self.cfg = cfg
        
        # --- ç¯å¢ƒä¸è·¯å¾„ ---
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.model.to(self.device)
        self.work_dir = Path(cfg.work_dir)
        self.work_dir.mkdir(parents=True, exist_ok=True) # ç¡®ä¿å·¥ä½œç›®å½•å­˜åœ¨
        
        # --- è®­ç»ƒè¿‡ç¨‹ä¸­çš„çŠ¶æ€å˜é‡ ---
        self.epoch = 0
        self.global_iter = 0
        self.inner_iter = 0
        self.max_epochs = cfg.total_epochs
        
        # âœ¨ ä½¿ç”¨ hasattr æ£€æŸ¥å¯é€‰å‚æ•°ï¼Œä½¿ Runner æ›´å¥å£®
        self.max_iters_per_epoch = cfg.steps_per_epoch if hasattr(cfg, 'steps_per_epoch') else len(self.train_loader)

        self.outputs = {}      # ç”¨äºåœ¨é’©å­ä¹‹é—´ä¼ é€’ä¸´æ—¶æ•°æ® (å¦‚loss, metrics)
        self.best_metric = 0.0 # ç”¨äºä¿å­˜æœ€ä½³æ¨¡å‹çš„åˆ¤æ–­ä¾æ®

    def call_hooks(self, event_name):
        """è°ƒç”¨æ‰€æœ‰é’©å­ä¸­åä¸º event_name çš„æ–¹æ³•ã€‚"""
        for hook in self.hooks:
            getattr(hook, event_name)(self)

    def train_epoch(self):
        """æ‰§è¡Œä¸€ä¸ªå®Œæ•´çš„è®­ç»ƒ epochã€‚"""
        self.model.train()
        progress_bar = tqdm(self.train_loader, total=self.max_iters_per_epoch, 
                            desc=f"Train Epoch {self.epoch + 1}/{self.max_epochs}")
                            
        for i, data_batch in enumerate(progress_bar):
            if i >= self.max_iters_per_epoch:
                break

            self.inner_iter = i
            self.call_hooks('before_iter')
            
            inputs = data_batch['image'].to(self.device)
            targets = data_batch['target'].to(self.device)
            
            self.optimizer.zero_grad()
            logits = self.model(inputs)
            loss = self.criterion(logits, targets)
            loss.backward()
            self.optimizer.step()
            
            self.global_iter += 1
            self.outputs['loss'] = loss.item()
            self.outputs['batch_size'] = inputs.size(0)
            self.current_lr = self.optimizer.param_groups[0]['lr']

            self.call_hooks('after_iter')
            progress_bar.set_postfix(loss=loss.item())

    @torch.no_grad()
    def validate_epoch(self):
        """
        æ‰§è¡Œä¸€ä¸ªå®Œæ•´çš„éªŒè¯ epochï¼Œå¹¶æ­£ç¡®åœ°è°ƒç”¨é’©å­ï¼Œä¸ºå¯è§†åŒ–æä¾›æ”¯æŒã€‚
        """
        self.model.eval()
        self.metric.reset()
        
        # 1. æ–°å¢ï¼šå¹¿æ’­â€œéªŒè¯epochå¼€å§‹â€äº‹ä»¶
        # è¿™ä¼šè§¦å‘ ValidationVisualizerHook çš„ before_val_epoch æ–¹æ³•
        self.call_hooks('before_val_epoch')

        val_losses = []
        progress_bar = tqdm(self.val_loader, desc=f"Validate Epoch {self.epoch + 1}")
        for i, data_batch in enumerate(progress_bar):
            self.inner_iter = i
            
            inputs = data_batch['image'].to(self.device)
            targets = data_batch['target'].to(self.device)
            logits = self.model(inputs)
            
            # 2. æ–°å¢ï¼šå°†å½“å‰æ‰¹æ¬¡çš„æ•°æ®æš‚å­˜åˆ° outputs ä¸­ï¼Œä¾›é’©å­è®¿é—®
            self.outputs['val_batch'] = data_batch
            self.outputs['val_logits'] = logits

            # è®¡ç®—æŸå¤±å’ŒæŒ‡æ ‡
            loss = self.criterion(logits, targets)
            val_losses.append(loss.item())
            self.metric.update(logits, data_batch)
            
            # 3. æ–°å¢ï¼šå¹¿æ’­â€œéªŒè¯iterç»“æŸâ€äº‹ä»¶
            # è¿™æ˜¯ ValidationVisualizerHook å·¥ä½œçš„å…³é”®ï¼
            self.call_hooks('after_val_iter')

        # è®¡ç®—å¹¶æ‰“å°æœ€ç»ˆç»“æœ
        eval_results = self.metric.compute()
        eval_results['loss'] = np.mean(val_losses)
        self.outputs['val_metrics'] = eval_results 
        print(f"Validation Results: {eval_results}")
        
        # 4. æ–°å¢ï¼šå¹¿æ’­â€œéªŒè¯epochç»“æŸâ€äº‹ä»¶
        self.call_hooks('after_val_epoch')

    def run(self):
        """å¯åŠ¨å®Œæ•´çš„è®­ç»ƒæµç¨‹ã€‚"""
        print("ğŸš€ Starting Runner...")
        self.call_hooks('before_run')
        
        for self.epoch in range(self.max_epochs):
            self.call_hooks('before_epoch')
            self.train_epoch()
            
            if (self.epoch + 1) % self.cfg.evaluation['interval'] == 0:
                self.validate_epoch()
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            current_f1 = self.outputs.get('val_metrics', {}).get('F1-Score', 0.0)
            if current_f1 > self.best_metric:
                self.best_metric = current_f1
                best_model_path = self.work_dir / 'best_model.pth'
                torch.save(self.model.state_dict(), best_model_path)
                print(f"ğŸ† New best model saved to {best_model_path} with F1-score: {self.best_metric:.4f}")
            
            # åªæœ‰åœ¨å­¦ä¹ ç‡è°ƒåº¦å™¨å­˜åœ¨æ—¶ï¼Œæ‰æ‰§è¡Œ .step()
            if self.lr_scheduler is not None:
                self.lr_scheduler.step()

            self.call_hooks('after_epoch')
            
        self.call_hooks('after_run')
        print("\nğŸ‰ Training finished!")
        print(f"Best F1-Score on validation set: {self.best_metric:.4f}")