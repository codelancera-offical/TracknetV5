# æ–‡ä»¶è·¯å¾„: ./scripts/preprocess_data.py (å·²ä¿®æ­£æ— çƒå¸§çš„å¤„ç†é€»è¾‘)

import numpy as np
import pandas as pd
import cv2
import argparse
from pathlib import Path
from tqdm import tqdm



def get_heatmap(h, w, cx, cy, r):

    x, y = np.meshgrid(np.linspace(1, w, w), np.linspace(1, h, h))
    # print(f'{x.shape}, {y.shape}')

    heatmap = ((y - (cy + 1)) ** 2) + ((x - (cx + 1)) ** 2)
    heatmap[heatmap <= r ** 2] = 1
    heatmap[heatmap > r ** 2] = 0
    return heatmap.astype(np.uint8) * 255


def process_data(input_dir: Path, output_dir: Path, mode: str, config: dict):
    gt_height, gt_width = config['gt_height'], config['gt_width']
    height, width = config['height'], config['width']

    ratio = gt_height / height
    radius = config['radius']

    label_files = sorted(list(input_dir.glob('**/Label.csv')))

    if not label_files:
        print(f"âŒ Error: No 'Label.csv' files found in the directory: {input_dir}")
        return

    all_clip_dfs = []

    print(f"ğŸš€ Starting data preprocessing for mode: '{mode}'...")
    for label_path in tqdm(label_files, desc="Processing Clips"):
        clip_df = pd.read_csv(label_path)
        clip_root = label_path.parent

        gt_clip_output_dir = output_dir / 'gts' / clip_root.relative_to(input_dir)
        gt_clip_output_dir.mkdir(parents=True, exist_ok=True)

        gt_paths = []
        # âœ¨âœ¨âœ¨ æ ¸å¿ƒæ”¹åŠ¨åŒºåŸŸå¼€å§‹ âœ¨âœ¨âœ¨
        for _, row in clip_df.iterrows():
            gt_path = gt_clip_output_dir / row['file name']
            gt_paths.append(str(gt_path.relative_to(output_dir)))

            # ä»…åœ¨çƒ­åŠ›å›¾æ–‡ä»¶ä¸å­˜åœ¨æ—¶åˆ›å»ºï¼Œé¿å…é‡å¤å·¥ä½œ
            if not gt_path.exists():
                # 1. é¦–å…ˆï¼Œåˆ›å»ºä¸€ä¸ªçº¯é»‘çš„ç”»å¸ƒ
                heatmap = np.zeros((gt_height, gt_width), dtype=np.uint8)

                # 2. åªæœ‰å½“çƒå¯è§ä¸”åæ ‡å­˜åœ¨æ—¶ï¼Œæ‰åœ¨ç”»å¸ƒä¸Šç”»é«˜æ–¯æ–‘ç‚¹
                if row['visibility'] != 0 and pd.notna(row['x-coordinate']):
                    x, y = int(row['x-coordinate']), int(row['y-coordinate'])
                    heatmap = get_heatmap(gt_height, gt_width, x * ratio, y * ratio, radius)


                # 3. æ— è®ºç”»å¸ƒä¸Šæ˜¯å¦æœ‰æ–‘ç‚¹ï¼Œéƒ½å°†å®ƒä¿å­˜ä¸‹æ¥
                cv2.imwrite(str(gt_path), heatmap)
        # âœ¨âœ¨âœ¨ æ ¸å¿ƒæ”¹åŠ¨åŒºåŸŸç»“æŸ âœ¨âœ¨âœ¨

        clip_df['gt_path'] = gt_paths
        base_path_col = clip_root.relative_to(input_dir)
        clip_df['path'] = [str(base_path_col / fname) for fname in clip_df['file name']]

        # âœ¨âœ¨âœ¨ æ–°å¢ï¼šä¸ºæ¯å¸§æ·»åŠ å‰åå¸§çš„ä¿¡æ¯ âœ¨âœ¨âœ¨
        if mode == 'past':
            # æ·»åŠ å‰ä¸€å¸§å’Œåä¸€å¸§çš„è·¯å¾„å’Œæ ‡ç­¾ä¿¡æ¯
            clip_df['path_prev'] = clip_df['path'].shift(1)
            clip_df['path_next'] = clip_df['path'].shift(-1)

            # æ·»åŠ å‰ä¸€å¸§å’Œåä¸€å¸§çš„gtè·¯å¾„
            clip_df['gt_path_prev'] = clip_df['gt_path'].shift(1)
            clip_df['gt_path_next'] = clip_df['gt_path'].shift(-1)

            # æ·»åŠ å‰ä¸€å¸§å’Œåä¸€å¸§çš„åæ ‡ä¿¡æ¯
            clip_df['x_prev'] = clip_df['x-coordinate'].shift(1)
            clip_df['y_prev'] = clip_df['y-coordinate'].shift(1)
            clip_df['x_next'] = clip_df['x-coordinate'].shift(-1)
            clip_df['y_next'] = clip_df['y-coordinate'].shift(-1)

            # æ·»åŠ å‰ä¸€å¸§å’Œåä¸€å¸§çš„visibilityå’Œstatus
            clip_df['visibility_prev'] = clip_df['visibility'].shift(1)
            clip_df['status_prev'] = clip_df['status'].shift(1)
            clip_df['visibility_next'] = clip_df['visibility'].shift(-1)
            clip_df['status_next'] = clip_df['status'].shift(-1)

        elif mode == 'context':
            # æ·»åŠ å‰ä¸€å¸§å’Œåä¸€å¸§çš„è·¯å¾„å’Œæ ‡ç­¾ä¿¡æ¯
            clip_df['path_prev'] = clip_df['path'].shift(1)
            clip_df['path_next'] = clip_df['path'].shift(-1)

            # æ·»åŠ å‰ä¸€å¸§å’Œåä¸€å¸§çš„gtè·¯å¾„
            clip_df['gt_path_prev'] = clip_df['gt_path'].shift(1)
            clip_df['gt_path_next'] = clip_df['gt_path'].shift(-1)

            # æ·»åŠ å‰ä¸€å¸§å’Œåä¸€å¸§çš„åæ ‡ä¿¡æ¯
            clip_df['x_prev'] = clip_df['x-coordinate'].shift(1)
            clip_df['y_prev'] = clip_df['y-coordinate'].shift(1)
            clip_df['x_next'] = clip_df['x-coordinate'].shift(-1)
            clip_df['y_next'] = clip_df['y-coordinate'].shift(-1)

            # æ·»åŠ å‰ä¸€å¸§å’Œåä¸€å¸§çš„visibilityå’Œstatus
            clip_df['visibility_prev'] = clip_df['visibility'].shift(1)
            clip_df['status_prev'] = clip_df['status'].shift(1)
            clip_df['visibility_next'] = clip_df['visibility'].shift(-1)
            clip_df['status_next'] = clip_df['status'].shift(-1)

        # åˆ é™¤é¦–å°¾å¸§ï¼ˆå› ä¸ºå®ƒä»¬æ²¡æœ‰å®Œæ•´çš„å‰åå¸§ï¼‰
        clip_df = clip_df.iloc[1:-1]

        all_clip_dfs.append(clip_df)

    print("âœ… All clips processed. Concatenating and creating temporal relationships...")
    master_df = pd.concat(all_clip_dfs, ignore_index=True)

    # âœ¨âœ¨âœ¨ ä¿®æ”¹æœ€ç»ˆçš„åˆ—é€‰æ‹© âœ¨âœ¨âœ¨
    if mode == 'past':
        final_columns = [
            'path_prev', 'path', 'path_next',  # ä¸‰å¼ å›¾ç‰‡è·¯å¾„ï¼šå‰ä¸€å¸§ã€å½“å‰å¸§ã€åä¸€å¸§
            'gt_path_prev', 'gt_path', 'gt_path_next',  # ä¸‰å¼ å¯¹åº”çš„gtå›¾è·¯å¾„
            'x_prev', 'y_prev', 'x-coordinate', 'y-coordinate', 'x_next', 'y_next',  # ä¸‰ä¸ªx,yåæ ‡
            'visibility_prev', 'visibility', 'visibility_next',  # ä¸‰ä¸ªvisibility
            'status_prev', 'status', 'status_next'  # ä¸‰ä¸ªstatus
        ]
    elif mode == 'context':
        final_columns = [
            'path_prev', 'path', 'path_next',  # ä¸‰å¼ å›¾ç‰‡è·¯å¾„ï¼šå‰ä¸€å¸§ã€å½“å‰å¸§ã€åä¸€å¸§
            'gt_path_prev', 'gt_path', 'gt_path_next',  # ä¸‰å¼ å¯¹åº”çš„gtå›¾è·¯å¾„
            'x_prev', 'y_prev', 'x-coordinate', 'y-coordinate', 'x_next', 'y_next',  # ä¸‰ä¸ªx,yåæ ‡
            'visibility_prev', 'visibility', 'visibility_next',  # ä¸‰ä¸ªvisibility
            'status_prev', 'status', 'status_next'  # ä¸‰ä¸ªstatus
        ]

    final_df = master_df[final_columns]

    # é‡å‘½ååˆ—ä»¥ä¿æŒä¸€è‡´æ€§
    column_rename = {
        'x-coordinate': 'x_current',
        'y-coordinate': 'y_current',
        'visibility': 'visibility_current',
        'status': 'status_current'
    }
    final_df = final_df.rename(columns=column_rename)

    final_df = final_df.sample(frac=1, random_state=42).reset_index(drop=True)
    num_train = int(len(final_df) * config['train_rate'])

    df_train = final_df.iloc[:num_train]
    df_val = final_df.iloc[num_train:]

    train_csv_path = output_dir / f"labels_{mode}_train.csv"
    val_csv_path = output_dir / f"labels_{mode}_val.csv"

    df_train.to_csv(train_csv_path, index=False)
    df_val.to_csv(val_csv_path, index=False)

    print(f"ğŸ‰ Preprocessing for mode '{mode}' complete!")
    print(f"Train samples: {len(df_train)}, saved to {train_csv_path}")
    print(f"Validation samples: {len(df_val)}, saved to {val_csv_path}")

    # æ‰“å°ç¬¬ä¸€è¡Œæ•°æ®ä½œä¸ºç¤ºä¾‹
    print("\nğŸ“Š Example of first row in final dataset:")
    print(f"Image paths: {df_train.iloc[0]['path_prev']}, {df_train.iloc[0]['path']}, {df_train.iloc[0]['path_next']}")
    print(
        f"GT paths: {df_train.iloc[0]['gt_path_prev']}, {df_train.iloc[0]['gt_path']}, {df_train.iloc[0]['gt_path_next']}")
    print(
        f"Coordinates: ({df_train.iloc[0]['x_prev']}, {df_train.iloc[0]['y_prev']}), ({df_train.iloc[0]['x_current']}, {df_train.iloc[0]['y_current']}), ({df_train.iloc[0]['x_next']}, {df_train.iloc[0]['y_next']})")
    print(
        f"Visibility: {df_train.iloc[0]['visibility_prev']}, {df_train.iloc[0]['visibility_current']}, {df_train.iloc[0]['visibility_next']}")
    print(
        f"Status: {df_train.iloc[0]['status_prev']}, {df_train.iloc[0]['status_current']}, {df_train.iloc[0]['status_next']}")


if __name__ == '__main__':
    # parser = argparse.ArgumentParser(description="TrackNet Dataset Preprocessing Script")
    # parser.add_argument('--input_dir', '-in', type=str, required=True, help='Path to the raw data directory.')
    # parser.add_argument('--output_dir', '-out', type=str, required=True,
    #                     help='Path to save the processed data and labels.')
    # parser.add_argument('--mode', '-m', type=str, required=True, choices=['past', 'context'], help="Processing mode.")
    # parser.add_argument('--height', type=int, default=720, help='Target image height.')
    # parser.add_argument('--width', type=int, default=1280, help='Target image width.')
    # parser.add_argument('--gt_height', '-gt_h', type=int, default=288, help='heatmap height.')
    # parser.add_argument('--gt_width', '-gt_w', type=float, default=512, help='heatmap width.')
    # parser.add_argument('--radius', type=float, default=2.5, help='radius of heatmap position.')
    # parser.add_argument('--train_rate', type=float, default=0.7, help='Proportion of the dataset to use for training.')
    #
    # args = parser.parse_args()

    config = {
        'height': 720,
        'width': 1280,
        'train_rate': 0.7,
        'gt_height': 288,
        'gt_width': 512,
        'radius': 2.5
    }

    input_path = Path('E:\\tracknet\TracknetV5\data\\v2')
    output_path = Path('E:\\tracknet\TracknetV5\data\\v2')

    process_data(input_path, output_path, 'context', config)